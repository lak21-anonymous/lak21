{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ok so this specific order of imports cannot be changed or else you get some bizarre error  \n",
    "- If an error pops up when importing try restarting the kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'nltk'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b1ef80bfcb55>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpreprocess\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutilities\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mconstants\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mitx-utilities/surveys/preprocess.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpkg_resources\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'nltk'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "\n",
    "from preprocess import *\n",
    "from utilities import *\n",
    "from constants import *\n",
    "from supervised_sentiment_analysis import *\n",
    "from skip_thought_vectors import *\n",
    "from graphing import *\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Encode preprocessed answers as thought vectors, and add them as a column to merged_results\n",
    "- Some (two, specifically) of the entries are encoded as nan because they are too long, these are filtered out by vectorized_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_results = pickle.load(open('merged_results.pickle', 'rb'))\n",
    "merged_results['Valid Vector'] = merged_results['Skip Thought Vector'].apply(lambda x: ~np.isnan(x).any())\n",
    "removed_results = merged_results[~merged_results['Valid Vector']]\n",
    "merged_results = merged_results[merged_results['Valid Vector']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_results['Categorical Tag'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "[print(f\"{len(answer.split())} \\n{answer}\") for answer in removed_results['Answer']]\n",
    "# Model really doesn't like long responses for some reason"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_nn('i wrote pseudocode', merged_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_CLUSTERS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_results = merged_results[merged_results['Categorical Tag'] != 'no tag']\n",
    "q1_labeled_results = labeled_results[labeled_results['Question'] == Q1]\n",
    "q1_features = np.array(q1_labeled_results['Skip Thought Vector'].tolist())\n",
    "q1_labels = np.array(q1_labeled_results['Categorical Tag'])\n",
    "q1_labeled_results[q1_labeled_results['Categorical Tag'] == 'negative'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model_confusion_matrix(q1_features, q1_labels, model = 'rfc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model_confusion_matrix(q1_features, q1_labels, model = 'svc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRIALS = 1\n",
    "SPLITS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.array(q1_labeled_results['Skip Thought Vector'].tolist())\n",
    "labels = np.array(q1_labeled_results['Categorical Tag'])\n",
    "\n",
    "conf_matrices = get_conf_matrices(features, labels, clfs = ['svc', 'gnb', 'rfc'], trials = TRIALS, splits = SPLITS, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_average_heatmaps(confusion_matrices, normalize = True, trials = 1, splits = 10, figsize = (8,8)):\n",
    "    average_confusion_matrices = copy.deepcopy(confusion_matrices)\n",
    "    clf_names = {\n",
    "        'svc': 'Support Vector Classifier',\n",
    "        'gnb': 'Gaussian Naive Bayes',\n",
    "        'rfc': 'Random Forest Classifier'\n",
    "    }\n",
    "    l = len(confusion_matrices)\n",
    "    fig, axs = plt.subplots(l, squeeze=False, figsize = (figsize[0],figsize[1] * l), gridspec_kw={'hspace': 0.2, 'wspace': 0})\n",
    "    pos = 0\n",
    "    \n",
    "    for clf, matrices in average_confusion_matrices.items():\n",
    "        average_confusion_matrix = sum(matrices)/len(matrices)\n",
    "        print(average_confusion_matrix)\n",
    "        stdev_matrix = np.std(matrices, axis=0)\n",
    "        figs = 2\n",
    "        def round_int(string):\n",
    "            return string[:figs] if '.' not in string[:figs] else string[:figs+1]\n",
    "        vfunc = np.vectorize(round_int)\n",
    "        def signif(x, p):\n",
    "            x = np.asarray(x)\n",
    "            x_positive = np.where(np.isfinite(x) & (x != 0), np.abs(x), 10**(p-1))\n",
    "            mags = 10 ** (p - 1 - np.floor(np.log10(x_positive)))\n",
    "            rounded = np.round(x * mags) / mags\n",
    "            vfunc = np.vectorize(lambda x: x[:-2] if len(x) == p+2 and x[-2:] == '.0' else x)\n",
    "            return vfunc(rounded.astype(str))\n",
    "        \n",
    "    \n",
    "        str_mean_matrix = signif(average_confusion_matrix, figs).astype(str)\n",
    "        str_stdev_matrix = signif(stdev_matrix, figs).astype(str)\n",
    "        annot_array = np.core.defchararray.add(str_mean_matrix, '\\n(')\n",
    "        annot_array = np.core.defchararray.add(annot_array, str_stdev_matrix)\n",
    "        annot_array = np.core.defchararray.add(annot_array, ')')\n",
    "        if normalize:\n",
    "            average_confusion_matrix = normalized(average_confusion_matrix, axis = 1, order = 1)\n",
    "        vmin = 0 if normalize else None\n",
    "        vmax = 1 if normalize else None\n",
    "        ax = axs[pos,0]\n",
    "        print(ax)\n",
    "        pos+=1\n",
    "        sns.heatmap(average_confusion_matrix, cmap=plt.cm.Blues, ax = ax, \n",
    "                    vmin = vmin, vmax = vmax, \n",
    "                    square = True, annot = annot_array, \n",
    "                    xticklabels = CLASS_NAMES, yticklabels = CLASS_NAMES, fmt = '',\n",
    "                    annot_kws={\"fontsize\":16})\n",
    "        ax.set_yticklabels(rotation = 0, size = 14, labels = CLASS_NAMES)\n",
    "        ax.set_xticklabels(size = 14, labels = CLASS_NAMES)\n",
    "        trial_string = '' if trials == 1 else str(trials)+\" trials, \"\n",
    "        normalized_string = 'Normalized ' if normalize else ''\n",
    "        title = f\"{normalized_string}Confusion Matrix using\\n{clf_names[clf]}, {trial_string}{str(splits)} splits\"\n",
    "        ax.set_title(title, size = 18)\n",
    "        ax.set_xlabel('Predicted Label', size = 16)\n",
    "        ax.set_ylabel('True Label', size = 16)\n",
    "\n",
    "svc_dict = {'svc': conf_matrices['svc']}\n",
    "get_average_heatmaps(svc_dict, trials = TRIALS, splits = SPLITS, normalize = False, figsize = (8,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_count = 10\n",
    "get_cross_validation_scores(features, labels, svm.SVC(), cv_count = cv_count)\n",
    "get_cross_validation_scores(features, labels, RandomForestClassifier(), cv_count = cv_count)\n",
    "get_cross_validation_scores(features, labels, GaussianNB(), cv_count = cv_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_tags = {\n",
    "    'positive': 1,\n",
    "    'neutral': 0,\n",
    "    'negative': -1\n",
    "}\n",
    "q1_numerical_tags = q1_labeled_results['Categorical Tag'].apply(lambda x: numerical_tags[x])\n",
    "scatter_plot(q1_features, labels = q1_numerical_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = svm.SVC()\n",
    "rfc = RandomForestClassifier()\n",
    "gnb = GaussianNB()\n",
    "for clf in [svc, rfc, gnb]:\n",
    "    arr = np.array(get_kappa(features, labels, clf, trials = SPLITS))\n",
    "    print(arr.mean(), arr.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for clf, conf_matrix in conf_matrices.items():\n",
    "    macro_F_scores = []\n",
    "    print(clf)\n",
    "    for conf_matrix in conf_matrix:\n",
    "        macro_F_scores.append(macro_F(conf_matrix))\n",
    "    print((np.mean(macro_F_scores), np.std(macro_F_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q2_results = merged_results[merged_results['Question'] == Q2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = 10\n",
    "reduced_q2_encodings = reduce_dimensions(list(q2_results['Skip Thought Vector']))\n",
    "agg_labels, model = get_agg_clusters(list(q2_results['Skip Thought Vector']), n_clusters = n_clusters)\n",
    "q2_results['Agg Label'] = agg_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_clusters(results, cluster_count = n_clusters, sample_size = 5):\n",
    "    for k in range(cluster_count):\n",
    "        print(k, '\\n', '\\n')\n",
    "        labels_k = results[results['Agg Label'] == k]\n",
    "        [print(answer, '\\n') for answer in labels_k['Answer'].sample(n=sample_size, replace = True)]\n",
    "\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scatter_plot(reduced_q2_encodings, labels = agg_labels, tsne = False, title = 'Reduced Dimension Skip-Thought Vectors', show_legend = True, cmap = plt.cm.nipy_spectral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_q2_results = q2_results[q2_results['Agg Label'] < 4]\n",
    "reduced_filtered_q2_encodings = reduce_dimensions(list(filtered_q2_results['Skip Thought Vector']))\n",
    "filtered_agg_labels, filtered_model = get_agg_clusters(reduced_filtered_q2_encodings, n_clusters = n_clusters)\n",
    "filtered_q2_results['Agg Label'] = filtered_agg_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_clusters(filtered_q2_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_plot(reduced_filtered_q2_encodings, labels = filtered_agg_labels, tsne = False, show_legend = True, cmap = plt.cm.nipy_spectral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_q1_labeled_results = labeled_results[labeled_results['Question'] == Q1]\n",
    "long_q1_labeled_results = long_q1_labeled_results[long_q1_labeled_results['Answer'].str.split().str.len() > 3]\n",
    "long_q1_features = np.array(long_q1_labeled_results['Skip Thought Vector'].tolist())\n",
    "long_q1_labels = np.array(long_q1_labeled_results['Categorical Tag'])\n",
    "plot_model_confusion_matrix(long_q1_features, long_q1_labels, model = 'svc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(long_q1_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(q1_labeled_results[q1_labeled_results['Answer'].str.split().str.len() > 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(q1_features, q1_labels, test_size=0.3)\n",
    "long_X_train, long_X_test, long_y_train, long_y_test = train_test_split(long_q1_features, long_q1_labels, test_size=0.3)\n",
    "clf = svm.SVC()\n",
    "\n",
    "\n",
    "# fit model and predict labels\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred=clf.predict(long_X_test)\n",
    "\n",
    "# create confusion matrix\n",
    "class_names = ['positive', 'neutral', 'negative']\n",
    "conf_mat = confusion_matrix(long_y_test, y_pred, labels= class_names)\n",
    "\n",
    "#graphing stuff\n",
    "titles_options = [(\"Confusion matrix, without normalization\", None),\n",
    "                  (\"Normalized confusion matrix\", 'true')]\n",
    "for title, normalize in titles_options:\n",
    "    disp = plot_confusion_matrix(clf, long_X_test, long_y_test,\n",
    "                                 display_labels=class_names,\n",
    "                                 cmap=plt.cm.Blues,\n",
    "                                 normalize=normalize)\n",
    "    disp.ax_.set_title(title)\n",
    "\n",
    "    print(title)\n",
    "    print(disp.confusion_matrix)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "def reduce_dimensions_50(X):\n",
    "    PCA_50 = PCA(n_components=50)\n",
    "    X_r = PCA_50.fit_transform(X)\n",
    "    return X_r\n",
    "\n",
    "pca_results = list(reduce_dimensions_50(list(q1_labeled_results['Skip Thought Vector'])))\n",
    "q1_labeled_results['50 dim'] = pca_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model_confusion_matrix(list(q1_labeled_results['50 dim']), list(q1_labeled_results['Categorical Tag']), model = 'gnb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
