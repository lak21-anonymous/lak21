{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'nltk'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-5bb193d3eb54>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutilities\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mconstants\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpreprocess\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgraphing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mitx-utilities/surveys/preprocess.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpkg_resources\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'nltk'"
     ]
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from utilities import *\n",
    "from constants import *\n",
    "from preprocess import *\n",
    "from graphing import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_results = preprocess(DATA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These files and their respective papers can all be downloaded from \n",
    "    http://www.cs.uic.edu/~liub/FBS/sentiment-analysis.html\n",
    "\n",
    " If you use this list, please cite the following paper:\n",
    "\n",
    "   Minqing Hu and Bing Liu. \"Mining and Summarizing Customer Reviews.\" \n",
    "       Proceedings of the ACM SIGKDD International Conference on Knowledge \n",
    "       Discovery and Data Mining (KDD-2004), Aug 22-25, 2004, Seattle, \n",
    "       Washington, USA, \n",
    "\n",
    "Notes: \n",
    "    1. The appearance of an opinion word in a sentence does not necessarily  \n",
    "       mean that the sentence expresses a positive or negative opinion. \n",
    "       See the paper below:\n",
    "       Bing Liu. \"Sentiment Analysis and Subjectivity.\" An chapter in \n",
    "          Handbook of Natural Language Processing, Second Edition, \n",
    "         (editors: N. Indurkhya and F. J. Damerau), 2010.\n",
    "    2. You will notice many misspelled words in the list. They are not \n",
    "       mistakes. They are included as these misspelled words appear \n",
    "       frequently in social media content.\n",
    "       \n",
    "### TODO: Remove mispelled words because they are caught by spellcheck?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NEGATIVE_WORDS = list(map(str.strip, list(open(NEGATIVE_WORDS_FILE, 'r'))))\n",
    "POSITIVE_WORDS = list(map(str.strip, list(open(POSITIVE_WORDS_FILE, 'r'))))\n",
    "assert '' not in NEGATIVE_WORDS and '' not in POSITIVE_WORDS\n",
    "\n",
    "for word in NEGATIVE_WORDS:\n",
    "    assert '\\n' not in word\n",
    "    if word in POSITIVE_WORDS: print(word)\n",
    "for word in POSITIVE_WORDS:\n",
    "    assert '\\n' not in word\n",
    "    if word in NEGATIVE_WORDS: print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "POSITIVE_EMOTICONS = [\":)\", \":D\", \":-)\", \":-D\", \";D\", \";-D\"]\n",
    "NEGATIVE_EMOTICONS = [\":(\", \":'(\", \":-(\", \";(\", \">:(\", \"=(\", \";-(\", \">:-(\", \">.<\"]\n",
    "NEGATION_WORDS = [\"not\", \"yet\", \"never\", \"nowhere\", \"nobody\", \"none\", \"nothing\", \"hardly\", \"scarcely\"]\n",
    "POSITIVE = 1\n",
    "NEGATIVE = -1\n",
    "NEUTRAL = 0\n",
    "DEFAULT_NEGATION_WINDOW = 5\n",
    "\n",
    "def scale_number(unscaled, to_min, to_max, from_min, from_max):\n",
    "    return (to_max - to_min) * (unscaled - from_min) / (from_max - from_min) + to_min\n",
    "\n",
    "def get_sentiment(words):\n",
    "    \"\"\" \n",
    "    The words should be filtered, tokenized, etc. before calling this function.\n",
    "    \"\"\"\n",
    "\n",
    "    orientation = NEUTRAL\n",
    "    negation_flag = False\n",
    "    negation_window = DEFAULT_NEGATION_WINDOW\n",
    "    n_tokens = 0\n",
    "    \n",
    "    for word in words:\n",
    "        if word in POSITIVE_EMOTICONS:\n",
    "            orientation = POSITIVE\n",
    "            n_tokens += 1\n",
    "            break\n",
    "        elif word in NEGATIVE_EMOTICONS:\n",
    "            orientation = NEUTRAL\n",
    "            n_tokens += 1\n",
    "            break\n",
    "        \n",
    "        if word in NEGATION_WORDS:\n",
    "            #n_tokens += 1\n",
    "            negation_flag = True\n",
    "            negation_window = DEFAULT_NEGATION_WINDOW\n",
    "            #orientation -= 1\n",
    "        \n",
    "        if word in POSITIVE_WORDS:\n",
    "            n_tokens += 1\n",
    "            orientation += -1 if negation_flag else 1\n",
    "            print(word, orientation)\n",
    "        elif word in NEGATIVE_WORDS:\n",
    "            n_tokens += 1\n",
    "            orientation += 1 if negation_flag else -1\n",
    "            print(word, orientation)\n",
    "        \n",
    "        negation_window -= 1\n",
    "        if negation_window == 0:\n",
    "            negation_flag = False\n",
    "    \n",
    "    # TODO: IS THIS RIGHT???\n",
    "    orientation /= max(n_tokens, 1)\n",
    "    #orientation = scale_number(orientation, 0, 1, -1, 1)\n",
    "    \n",
    "    return orientation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = 'it was not good'\n",
    "normalized = normalize(sentence)\n",
    "print(normalized)\n",
    "print(get_sentiment(normalized.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTES:** classifies \"problem\" as negative even though its a synonym for \"solution\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_sentiment(['I', 'am', 'having', 'a', 'lot', 'of', 'trouble', 'this', 'problem', 'is', 'way', 'too', 'difficult']))\n",
    "print(get_sentiment(['I', 'do', 'not', 'know', 'how', 'to', 'do', 'this', 'problem', 'but', 'i', 'love', 'this', 'problem']))\n",
    "print(get_sentiment(['I', 'need', 'help'])) # This should be negative\n",
    "print(get_sentiment(\"I love this question, and I love coding.\".split()))\n",
    "print(get_sentiment(\"I love this question, but I hate coding.\".split()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for problem in survey_results:\n",
    "    results = survey_results[problem]\n",
    "    results['Words'] = results['Answer'].str.split().str.len()\n",
    "    survey_results[problem] = results[results['Words'] > 0]\n",
    "    assert 0 not in survey_results[problem]['Words'].unique()\n",
    "\n",
    "for results in survey_results.values():\n",
    "    assert 0 not in results['Words'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- set up vader sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "analyser = SentimentIntensityAnalyzer()\n",
    "def get_vader_sentiment(sentence):\n",
    "    return analyser.polarity_scores(sentence)['compound']\n",
    "\n",
    "\n",
    "for problem, results in survey_results.items():\n",
    "    results['Vader'] = results['Answer'].apply(lambda x: get_vader_sentiment(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average_sentiment(data, key = 'Sentiment'):\n",
    "    return np.mean(np.array(data[key]))\n",
    "\n",
    "def get_student_Q1_Q2_means(student_results, key= 'Sentiment'):\n",
    "    student_Q1_Q2_means = []\n",
    "    for student, results in student_results.items():\n",
    "        if not results[results['Question']==Q1].empty and not results[results['Question']==Q2].empty:\n",
    "            Q1_mean = np.mean(np.array(results[results['Question']==Q1][key]))\n",
    "            Q2_mean = np.mean(np.array(results[results['Question']==Q2][key]))\n",
    "            student_Q1_Q2_means.append([Q1_mean, Q2_mean])\n",
    "    \n",
    "    return np.array(student_Q1_Q2_means)\n",
    "merged_results = merge_problem_data(survey_results)\n",
    "\n",
    "student_results = get_student_results(merged_results)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Divide data into positive, neutral and negative based on thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition(data, key, endpoints, include_extremes = True):\n",
    "    partitions = {}\n",
    "    for k in range(len(endpoints)-1):\n",
    "        dict_key = \"[{0},{1})\".format(endpoints[k], endpoints[k+1])\n",
    "        partitions[dict_key] = data[(data[key] >= endpoints[k]) & (data[key]<endpoints[k+1])]\n",
    "    if include_extremes:\n",
    "        partitions[\"[,{0})\".format(endpoints[0])] = data[data[key] < endpoints[0]]\n",
    "        partitions[\"[{0},)\".format(endpoints[len(endpoints)-1])] = data[data[key] >= endpoints[len(endpoints)-1]]\n",
    "    return partitions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "part = partition(merged_results[merged_results['Question']==Q2], 'Vader', [-1.1, -0.2, 0.2, 1.1], include_extremes=False)\n",
    "for interval in part.keys():\n",
    "    part[interval] = partition(part[interval], 'Sentiment', [-0.1, 0.4, 0.6, 1.1], include_extremes=False)\n",
    "    part[interval] = [len(p) for i, p in part[interval].items()]\n",
    "arr = np.array([a for a in part.values()])\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_results = get_manual_tags(merged_results, 'manual_tags_Q1.csv')\n",
    "merged_results = get_manual_tags(merged_results, 'manual_tags_Q2.csv')\n",
    "labeled_results = merged_results[~(merged_results['Manual Tag'] == 'no tag')]\n",
    "labeled_results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_categorical_tag_from_sentiment(sentiment, neutral_threshold = 0.2):\n",
    "    if sentiment >= neutral_threshold:\n",
    "        return 'positive'\n",
    "    elif sentiment <= (-1) * neutral_threshold:\n",
    "        return 'negative'\n",
    "    return 'neutral'\n",
    "def get_categorical_array(data, key = 'Sentiment', neutral_threshold = 0.2):\n",
    "    if key == 'Sentiment':\n",
    "        return data[key].apply(lambda x: get_categorical_tag_from_sentiment(x, neutral_threshold = neutral_threshold))\n",
    "    return data[key].apply(lambda x: get_categorical_tag_from_sentiment(x, neutral_threshold = neutral_threshold))\n",
    "\n",
    "cat_array = get_categorical_array(labeled_results)\n",
    "lst = list(cat_array)\n",
    "print(len([l for l in lst if l =='positive']))\n",
    "print(len([l for l in lst if l =='neutral']))\n",
    "print(len([l for l in lst if l =='negative']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalized(a, axis=-1, order=2):\n",
    "    l1 = np.atleast_1d(np.linalg.norm(a, order, axis))\n",
    "    l1[l1==0] = 1\n",
    "    return a / np.expand_dims(l1, axis)\n",
    "\n",
    "def categorical_heatmap(y, y_pred, title = '', normalize = False):\n",
    "    cf_matrix = confusion_matrix(y, y_pred, labels = CLASS_NAMES)\n",
    "    if normalize:\n",
    "        cf_matrix = normalized(cf_matrix, axis = 1, order = 1)\n",
    "        sns.heatmap(cf_matrix, annot=True, cmap='Blues', xticklabels=CLASS_NAMES, yticklabels = CLASS_NAMES, square = True, vmin = 0, vmax = 1)\n",
    "    else:\n",
    "        sns.heatmap(cf_matrix, annot=True, cmap='Blues', xticklabels=CLASS_NAMES, yticklabels = CLASS_NAMES, square = True, fmt = 'd')\n",
    "    plt.yticks(rotation=0, size = 14)\n",
    "    plt.xticks(size = 14)\n",
    "    plt.xlabel('Predicted Label', fontsize=16)\n",
    "    plt.ylabel('True Label', fontsize=16)\n",
    "    plt.title(title, fontsize = 16)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1_labeled_results = labeled_results[labeled_results['Question'] == Q1]\n",
    "categorical_heatmap(q1_labeled_results['Categorical Tag'], \n",
    "                    get_categorical_array(q1_labeled_results, neutral_threshold = 0.3), \n",
    "                    title = 'Polar Sentiment Model', \n",
    "                    normalize = False)\n",
    "plt.show()\n",
    "categorical_heatmap(q1_labeled_results['Categorical Tag'], \n",
    "                    get_categorical_array(q1_labeled_results, neutral_threshold = 0.3, key = 'Vader'), \n",
    "                    title = 'Valence Sentiment Model', \n",
    "                    normalize = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from supervised_sentiment_analysis import *\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "correct_labels = list(q1_labeled_results['Categorical Tag'])\n",
    "vader_labels = list(get_categorical_array(q1_labeled_results, neutral_threshold = 0.3, key = 'Vader'))\n",
    "custom_labels = list(get_categorical_array(q1_labeled_results, neutral_threshold = 0.3, key = 'Sentiment'))\n",
    "print(cohen_kappa_score(correct_labels, vader_labels))\n",
    "print(cohen_kappa_score(correct_labels, custom_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "macro_F(confusion_matrix(correct_labels, vader_labels, labels = CLASS_NAMES))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "macro_F(confusion_matrix(correct_labels, custom_labels, labels = CLASS_NAMES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1_labeled_results['vader label'] = q1_labeled_results['Vader'].apply(get_categorical_tag_from_sentiment)\n",
    "q1_labeled_results['polar label'] = q1_labeled_results['Sentiment'].apply(get_categorical_tag_from_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
