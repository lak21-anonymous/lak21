{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start the Stanford CoreNLP server (which is necessary to run this code), run the following commands in the terminal:\n",
    "<pre><code>$ export PATH=~/jdk1.8.0_251/bin:$PATH\n",
    "$ cd ~/mitx-utilities/surveys/stanford-corenlp-full-2018-10-05\n",
    "$ java -mx4g -cp \"*\" edu.stanford.nlp.pipeline.StanfordCoreNLPServer -annotators \"tokenize,ssplit,pos,lemma,parse\" -port 9000 -timeout 30000\n",
    "</code></pre>\n",
    "\n",
    "Might need to change the second line to \n",
    "\n",
    "if you access from different home directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'nltk'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-d434ab463ec4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpycorenlp\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStanfordCoreNLP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'nltk'"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import re\n",
    "from pycorenlp import StanfordCoreNLP\n",
    "import matplotlib\n",
    "import pickle\n",
    "nlp=StanfordCoreNLP(\"http://localhost:9000/\")\n",
    "\n",
    "from preprocess import *\n",
    "from utilities import *\n",
    "from constants import *\n",
    "from supervised_sentiment_analysis import *\n",
    "from graphing import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sent = \"The problem was fairly straightforward, taking into account the work already done in problems 1 & 2, and the finger exercises using bisection search.  The one thing that could have tripped me up was what test to use for when arrived at answer.  At first I thought >0 and <0, then realized that it would try to get exact to many decimals, which was unnecessary and might be impossible.  So, used a comparison of > 0.01 < -0.01.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = \"The problem was fairly straightforward, taking into account the work already done in problems 1 & 2, and the finger exercises using bisection search.  The one thing that could have tripped me up was what test to use for when arrived at answer.  At first I thought >0 and <0, then realized that it would try to get exact to many decimals, which was unnecessary and might be impossible.  So, used a comparison of > 0.01 < -0.01.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- returns the high level verb phrases within a sentence\n",
    "- these are supposed to represent \"steps\" within the student's procedure\n",
    "- a phrase is added if it:\n",
    "    - is not part of another verb phrase\n",
    "    - does not contain any conjunctions\n",
    "- this is a pretty arbitrary criteria but it work pretty well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_verb_phrases(sentences):\n",
    "    # get parse trees of inputted sentences\n",
    "    parser = nlp.annotate(sentences, properties={\"annotators\":\"parse\",\"outputFormat\": \"json\"})\n",
    "    sent_trees = [nltk.tree.ParentedTree.fromstring(parser[\"sentences\"][k][\"parse\"]) for k in range(len(parser['sentences']))]\n",
    "    \n",
    "    # loop through the subtrees, adding those representing a verb phrase to sub_trees\n",
    "    sub_trees = []\n",
    "    \n",
    "    for sent_tree in sent_trees:\n",
    "        for sub_tree in list(sent_tree.subtrees()):\n",
    "\n",
    "            \n",
    "            # check if subtree is a verb phrase\n",
    "            if sub_tree.label() == \"VP\":\n",
    "                \n",
    "                # check if any parents are subtrees\n",
    "                # TODO: shorten/optimize this\n",
    "                parent = sub_tree.parent()\n",
    "                parent_contained = False\n",
    "                while parent != None:\n",
    "                    if parent in sub_trees:\n",
    "                        parent_contained = True\n",
    "                        break\n",
    "                    parent = parent.parent()\n",
    "                if parent_contained:\n",
    "                    continue\n",
    "                \n",
    "                # if verb phrase contains a conjuction, check if the conjuction splits up another verb phrase\n",
    "                # if it does, skip the verb phrase\n",
    "                # this is pretty arbitrary but works well in practice\n",
    "                if \"CC\" in [leaf[1] for leaf in sub_tree.pos()] and \"VP\" in [node.label() for node in sub_tree]:\n",
    "                    continue\n",
    "                sub_trees.append(sub_tree)\n",
    "                        \n",
    "         \n",
    "    # for each clause level subtree, extract relevant simple sentence and return list of them\n",
    "    clause_list = []\n",
    "    for t in sub_trees:\n",
    "        subject_phrase = ' '.join(t.leaves())\n",
    "        clause_list.append(subject_phrase)\n",
    "\n",
    "    return clause_list\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"explain or and operator with boolean true false in a bit more detail\"\n",
    "parser = nlp.annotate(sentence, properties={\"annotators\":\"parse\",\"outputFormat\": \"json\"})\n",
    "sent_trees = [nltk.tree.ParentedTree.fromstring(parser[\"sentences\"][k][\"parse\"]) for k in range(len(parser['sentences']))]\n",
    "[sent_tree.pretty_print() for sent_tree in sent_trees]\n",
    "print(get_verb_phrases(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = 'I copied my code from problem 2 as a starting point. I set up the logic for the bisection search such as the low, high, average of the two and the if loops for when it was too high or too low of a guess. After, I used the print and debugging features to figure out what was happening in my code and did find that i was entering an infinite loop since the balance never gets to 0 so i had to do some rounding.'\n",
    "get_verb_phrases(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first input text is:\n",
    "> The problem was fairly straightforward, taking into account the work already done in problems 1 & 2, and the finger exercises using bisection search.  The one thing that could have tripped me up was what test to use for when arrived at answer.  At first I thought >0 and <0, then realized that it would try to get exact to many decimals, which was unnecessary and might be impossible.  So, used a comparison of > 0.01 < -0.01.\n",
    "\n",
    "The second is :\n",
    "> i went to the store, ran to the mall, debugged and filtered my code, then went to sleep, but couldn't fall asleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "text = \"The problem was fairly straightforward, taking into account the work already done in problems 1 & 2, and the finger exercises using bisection search.  The one thing that could have tripped me up was what test to use for when arrived at answer.  At first I thought >0 and <0, then realized that it would try to get exact to many decimals, which was unnecessary and might be impossible.  So, used a comparison of > 0.01 < -0.01.\"\n",
    "print(get_verb_phrases(text))\n",
    "\n",
    "sent = \"i went to the store, ran to the mall, debugged and filtered my code, then went to sleep, but couldn't fall asleep\"\n",
    "print(get_verb_phrases(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_results = pickle.load(open('merged_results.P', 'rb'))\n",
    "merged_results = get_manual_tags(merged_results, 'manual_tags_Q1.csv')\n",
    "merged_results = get_manual_tags(merged_results, 'manual_tags_Q2.csv')\n",
    "q2_results = merged_results[merged_results['Question'] == Q2]\n",
    "sample = q2_results.sample(n=100, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "results = q2_results\n",
    "results['index'] = np.arange(len(results))\n",
    "results = results.set_index('index')\n",
    "results['Phrase List'] = results['Original'].apply(get_verb_phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skip_thought_vectors import get_encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_phrases(phrase_list):\n",
    "    if len(phrase_list):\n",
    "        return get_encodings(phrase_list)\n",
    "    return []\n",
    "\n",
    "# TODO: Figure out why .apply doesn't work here\n",
    "results['Phrase Vectors'] = \"A\"\n",
    "count = 0\n",
    "chunk = max(results.shape[0]//10, 100)\n",
    "for index, row in results.iterrows():\n",
    "    phrase_vectors = encode_phrases(row['Phrase List'])\n",
    "    results.at[index, 'Phrase Vectors'] = phrase_vectors\n",
    "    if count + 1 % chunk == 0:\n",
    "        print(f\"{count} done out of {results.shape[0]}\")\n",
    "    count += 1\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_phrase_vectors = [phrase_vector for phrase_vectors in list(results['Phrase Vectors']) for phrase_vector in phrase_vectors]\n",
    "\n",
    "len(all_phrase_vectors)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- distribution of number of verb phrases in each response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase_counts = [len(phrase_vectors) for phrase_vectors in list(results['Phrase Vectors'])]\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(12, 6)\n",
    "bins = range(max(phrase_counts)+2)\n",
    "arr = ax.hist(phrase_counts, bins = bins, alpha = 0.8)\n",
    "bin_width = arr[1][1]-arr[1][0]\n",
    "for k in bins[:-1]:\n",
    "    if arr[0][k] > 0:\n",
    "        plt.text(arr[1][k]+bin_width/2,arr[0][k]+1,str(int(arr[0][k])), ha = 'center')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem_number = {\n",
    "    'fex1': 0,\n",
    "    'ps1': 1,\n",
    "    'fex2': 2,\n",
    "    'ps2': 3,\n",
    "    'fex4': 4,\n",
    "    'ps4' : 5\n",
    "    \n",
    "}\n",
    "print(results.columns)\n",
    "problem_numbers = list(results['Problem'].apply(lambda x: problem_number[x]))\n",
    "flattened_problem_numbers = [problem_numbers[k] for k in range(len(list(results['Phrase Vectors']))) for phrase_vector in list(results['Phrase Vectors'])[k]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- scatter plot of dimension-reduced verb phrases colored by problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scatter_plot(tsne_results, labels = flattened_problem_numbers, show_legend = True, legend_labels = problem_number.keys(), tsne = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
